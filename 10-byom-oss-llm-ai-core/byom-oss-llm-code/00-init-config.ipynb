{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial configuration of SAP AI Core for BYOM-OSS-LLM-AI-CORE\n",
    "This notebook automates the initial configurations for application BYOM-OSS-LLM-AI-CORE to bring open-sourced llms into SAP AI Core. Alternatively, you can perform the same with SAP AI Launchpad.\n",
    "- Review and update the configuration in config.json\n",
    "- Initialize a client of SAP AI Core SDK\n",
    "- Create a resource group\n",
    "- Register a docker secret\n",
    "- Onboarding Git Repository and Create an Application for BYOM-OSS-LLM-AI-CORE\n",
    "- Synchronize the application and check its status\n",
    "- Create the configurations for scenarios ollama, local-ai, llama.cpp, and vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: Copy [config.template.json](config.template.jso) as [config.json](config.json) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "cp config.template.json config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: Review and Update configuration in [config.json](config.json)\n",
    "Please read the **comments** carefully in [config.json](config.json) and update the necessary configurations.  \n",
    "- **name**: used as name of git repository and application. \n",
    "- **resource_group**: \"default\" will be used if not specified. It is optional but recommended to create a dedicate resource group, and update it [config.json](config.json). By default, \"default\" resource group is in place for all the AI Core instances.AI Core with tree tier plan is not able to create a new resource group.\n",
    "- **ai_core_sk**: update with your own AI Core Service Key\n",
    "- **docker_secret** update with you own docker user and access token\n",
    "    - username: Replace <REPLACE_WITH_YOUR_DOCKER_USERNAME> with your docker user name. \n",
    "    - password: Replace <REPLACE_WITH_YOUR_DOCKER_ACCESS_TOKEN> with your docker access token.\n",
    "- **git_repo**: update the git repo configuration with your owns\n",
    "    - repo_url: url to your forked repository. It should be: https://github.com/<YOUR_GITHUB_ORG_OR_USER>/btp-generative-ai-hub-use-cases\n",
    "    - user: update with your github user\n",
    "    - access_token: update with your github user access token\n",
    "- **application**: The SAP AI Core application hosts the scenarios of ollama etc to serving open sourced llms in SAP AI Core\n",
    "    - path_in_repo: relative path to the serving templates. No change needed.\n",
    "- **configurations**: Review the configurations of the scenarios. By default, it is configured to load the mistral-7b quantization model with [resource plan infer.s in SAP AI Core](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/choose-resource-plan-c58d4e584a5b40a2992265beb9b6be3c) defined in [../byom-oss-llm-templates](../byom-oss-llm-templates). It is recommend to go ahead first with the default configurations in config.json.\n",
    "    - **Ollama**: No configuration required for ollama. Pull the model dynamically in [ollama/ollama.ipynb](ollama/ollama.ipynb)\n",
    "    - **LocalAI**: LocalAI enable you to [preload model during startup](https://localai.io/advanced/#preloading-models-during-startup). The initial configuration in config.json will preload model [Mistral-7B-OpenOrca-GGUF](https://github.com/go-skynet/model-gallery/blob/main/mistral.yaml) with local-ai on resource plan 'infer.s' defined in [local-ai-template.yaml](../byom-oss-llm-templates/local-ai-template.yaml). In its model config file, GPU acceleration isn't enabled, hence it is quite slow. To have GPU acceleration for a model, you may set in its model config yaml file. For example [mixtral-Q6.yaml](https://github.com/go-skynet/model-gallery/blob/main/mixtral-Q6.yaml). Please review the [full config model file reference](https://localai.io/advanced/#full-config-model-file-reference)\n",
    "        ```sh\n",
    "        f16: true \n",
    "        mmap: true \n",
    "        gpu_layers: xx \n",
    "        ```\n",
    "        In addition, you can install more models through end point /model/apply in [local-ai/local-ai.ipynb](local-ai/local-ai.ipynb). Please refer to https://localai.io/advanced/#preloading-models-during-startup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: Load the configurations from [config.json](config.json)\n",
    "The service key of AI Core are located in section ai_core_sk of [config.json](config.json).<br/>\n",
    "Please update it with your own service key before running this notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations loaded from config.json\n",
      "name:  byom-open-source-llms-tej-sap resource_group:  oss-llm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from time import sleep\n",
    "\n",
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Initializations\n",
    "resource_group = config.get(\"resource_group\", \"default\")\n",
    "name = config.get(\"name\", \"open-source-llms\")\n",
    "print(\"Configurations loaded from config.json\")\n",
    "print(\"name: \", name, \"resource_group: \", resource_group )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3: Initialize AI Core SDK Client\n",
    "The service key of AI Core are located in section ai_core_sk of [config.json](config.json).<br/>\n",
    "Please update it with your own service key before running this notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource group: oss-llm, name: byom-open-source-llms-tej-sap\n"
     ]
    }
   ],
   "source": [
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "from ai_core_sdk.models import ParameterBinding\n",
    "\n",
    "ai_core_sk = config[\"ai_core_service_key\"]\n",
    "client = AICoreV2Client(base_url=ai_core_sk.get(\"serviceurls\").get(\"AI_API_URL\")+\"/v2\",\n",
    "                        auth_url=ai_core_sk.get(\"url\")+\"/oauth/token\",\n",
    "                        client_id=ai_core_sk.get(\"clientid\"),\n",
    "                        client_secret=ai_core_sk.get(\"clientsecret\"),\n",
    "                        resource_group=resource_group)\n",
    "print(f\"resource group: {resource_group}, name: {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4: Create a dedicated resource group (Optional but recommended)\n",
    "resource_group defined here must be matched with resource_group in [config.json](config.json). Default as \"oss-llm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'resource_group_id': 'oss-llm', 'labels': None, 'status': None, 'created_at': None}\n"
     ]
    }
   ],
   "source": [
    "response = client.resource_groups.create(resource_group_id = resource_group)\n",
    "print(response.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Register Docker Secret within SAP AI Core\n",
    "\n",
    "Please skip this step if you have already registered your docker secret within SAP AI Core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Secret exists'}\n",
      "Docker Registry Secret: docker-secret\n"
     ]
    }
   ],
   "source": [
    "docker_secret = config[\"docker_secret\"]\n",
    "response = client.docker_registry_secrets.create(\n",
    "    name = docker_secret[\"name\"],\n",
    "    data = docker_secret[\"data\"]\n",
    ")\n",
    "\n",
    "print(response.__dict__)\n",
    "print(f'Docker Registry Secret: {docker_secret[\"name\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: Update the serving templates\n",
    "Please replace the place holders in the following serving templates.\n",
    "- <YOUR_DOCKER_SECRET> to be replaced with **docker-secret** created in step 5 or your own docker secret.\n",
    "- <YOUR_DOCKER_USER> to be replaced with your own docker hub user.\n",
    "- ai.sap.com/resourcePlan: By default, the resource plan is as **infer.s**, which is sufficient for 7B model in the sample tests notebooks afterwards. If you would like to run 13B or 30B beyond etc, please use **infer.m** or **infer.l** resource plan. Check out more detail about [Resource Plan in SAP AI Core](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/choose-resource-plan-c58d4e584a5b40a2992265beb9b6be3c).\n",
    "```yaml\n",
    "    metadata:\n",
    "      #...\n",
    "      labels: |\n",
    "        ai.sap.com/resourcePlan: infer.s\n",
    "    spec: |\n",
    "      predictor:\n",
    "        imagePullSecrets:\n",
    "          - name: <YOUR_DOCKER_SECRET>\n",
    "          ...\n",
    "        containers:\n",
    "            - name: kserve-container\n",
    "              image: docker.io/<YOUR_DOCKER_USER>/ollama:ai-core\n",
    "```\n",
    "- [../byom-oss-llm-templates/llama.cpp-template.yaml](../byom-oss-llm-templates/llama.cpp-template.yaml)\n",
    "- [../byom-oss-llm-templates/local-ai-template.yaml](../byom-oss-llm-templates/local-ai-template.yaml)\n",
    "- [../byom-oss-llm-templates/ollama-template.yaml](../byom-oss-llm-templates/ollama-template.yaml)\n",
    "- [../byom-oss-llm-templates/vllm-template.yaml](../byom-oss-llm-templates/vllm-template.yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7: Onboard github repository and create an application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AIAPIServerException",
     "evalue": "Failed to post /admin/repositories: Repository is already onboarded \n Status Code: 409, Request ID:None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAIAPIServerException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Onboard repository\u001b[39;00m\n\u001b[1;32m      2\u001b[0m repo_config \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgit_repo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m repository \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepositories\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepo_url\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43musername\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccess_token\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(repository)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create application\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ai_core_sdk/resource_clients/repositories_client.py:36\u001b[0m, in \u001b[0;36mRepositoriesClient.create\u001b[0;34m(self, name, url, username, password)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"On-boards a new GitOps repository\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m:param name: name of the GitOps repository\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m:rtype: class:`ai_core_sdk.models.base_models.BasicNameResponse`\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m body \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m: url, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m'\u001b[39m: username, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m'\u001b[39m: password}\n\u001b[0;32m---> 36\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Message\u001b[38;5;241m.\u001b[39mfrom_dict(response_dict)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ai_api_client_sdk/helpers/rest_client.py:140\u001b[0m, in \u001b[0;36mRestClient.post\u001b[0;34m(self, path, body, headers, resource_group)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m, body: Dict[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, headers: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    115\u001b[0m          resource_group: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request to the server.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    :param path: path of the endpoint the request should be sent to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    :rtype: dict\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_json\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_group\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ai_api_client_sdk/helpers/rest_client.py:106\u001b[0m, in \u001b[0;36mRestClient._handle_request\u001b[0;34m(self, method, path, params, body_json, headers, resource_group)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m AIAPIPreconditionFailedException(description\u001b[38;5;241m=\u001b[39merror_description, error_message\u001b[38;5;241m=\u001b[39merror_message,\n\u001b[1;32m    103\u001b[0m                                                error_code\u001b[38;5;241m=\u001b[39merror_code, request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[1;32m    104\u001b[0m                                                details\u001b[38;5;241m=\u001b[39merror_details)\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m AIAPIServerException(status_code\u001b[38;5;241m=\u001b[39mstatus_code, description\u001b[38;5;241m=\u001b[39merror_description,\n\u001b[1;32m    107\u001b[0m                                    error_message\u001b[38;5;241m=\u001b[39merror_message, error_code\u001b[38;5;241m=\u001b[39merror_code, request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[1;32m    108\u001b[0m                                    details\u001b[38;5;241m=\u001b[39merror_details)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AIAPIServerException(description\u001b[38;5;241m=\u001b[39merror_description, error_message\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext,\n\u001b[1;32m    111\u001b[0m                                status_code\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code)\n",
      "\u001b[0;31mAIAPIServerException\u001b[0m: Failed to post /admin/repositories: Repository is already onboarded \n Status Code: 409, Request ID:None"
     ]
    }
   ],
   "source": [
    "# Onboard repository\n",
    "repo_config = config[\"git_repo\"]\n",
    "repository = client.repositories.create(name,\n",
    "                                        url=repo_config.get(\"repo_url\"),\n",
    "                                        username=repo_config.get(\"user\"),\n",
    "                                        password=repo_config.get(\"access_token\")\n",
    "                                        )\n",
    "print(repository)\n",
    "\n",
    "# Create application\n",
    "app_config = config[\"application\"]\n",
    "application = client.applications.create(revision=app_config.get(\"revision\", \"HEAD\"),\n",
    "                                        path=app_config.get(\"path_in_repo\"),\n",
    "                                        application_name=name,\n",
    "                                        repository_name=name\n",
    "                                        )\n",
    "print(application)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8: Check if application has synced and scenario created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health Status: Healthy, Sync Status: OutOfSync, Sync Finished at: 2024-05-05T09:19:15Z\n",
      "Health Status: Healthy, Sync Status: OutOfSync, Sync Finished at: 2024-05-05T09:19:15Z\n",
      "Health Status: Healthy, Sync Status: OutOfSync, Sync Finished at: 2024-05-05T09:19:15Z\n",
      "Health Status: Healthy, Sync Status: OutOfSync, Sync Finished at: 2024-05-05T09:19:15Z\n",
      "Health Status: Healthy, Sync Status: OutOfSync, Sync Finished at: 2024-05-05T09:19:15Z\n",
      "Health Status: Healthy, Sync Status: OutOfSync, Sync Finished at: 2024-05-05T09:19:15Z\n",
      "Health Status: Healthy, Sync Status: OutOfSync, Sync Finished at: 2024-05-05T09:19:15Z\n",
      "Health Status: Healthy, Sync Status: OutOfSync, Sync Finished at: 2024-05-05T09:19:15Z\n",
      "Health Status: Healthy, Sync Status: OutOfSync, Sync Finished at: 2024-05-05T09:19:15Z\n",
      "Health Status: Healthy, Sync Status: OutOfSync, Sync Finished at: 2024-05-05T09:19:15Z\n",
      "Application not yet synced after 10 time retry. Please execute this cell again\n"
     ]
    }
   ],
   "source": [
    "max_tries = 10\n",
    "i = 0\n",
    "interval_s = 20\n",
    "while i < max_tries:\n",
    "    i = i +1\n",
    "    app_status = client.applications.get_status(name)\n",
    "    print(f\"Health Status: {app_status.health_status}, Sync Status: {app_status.sync_status}, Sync Finished at: {app_status.sync_finished_at}\" )\n",
    "    \n",
    "    if(app_status.sync_status == \"Synced\"):\n",
    "        break\n",
    "\n",
    "    # Synchronize the application and wait\n",
    "    client.applications.refresh(name) \n",
    "    sleep(interval_s)\n",
    "\n",
    "if app_status.sync_status == \"Synced\":\n",
    "    print(\"Application synced\")\n",
    "    # Check scenarios\n",
    "    scenarios = client.scenario.query()\n",
    "\n",
    "    scenario_list = config[\"scenarios\"]\n",
    "    for scenario in scenario_list:\n",
    "        scenario_name = scenario[\"name\"]\n",
    "        scenario_exists = scenario_name in [s.name for s in scenarios.resources]\n",
    "        print(f\"Scenario {scenario} synced\") if scenario_exists else print(f\"Scenario {scenario_name} not yet available\")\n",
    "\n",
    "else:\n",
    "    #print(f\"Application not yet synced after 10 time retry. Likely, something wrong in the templates under git repo {repository.url}/{app_config.get(\"path_in_repo\")}.\\nPlease check it. You can run this cell again once it is fixed.\")\n",
    "    print(f\"Application not yet synced after 10 time retry. Please execute this cell again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9: Create configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_json_file(file_path, key, value):\n",
    "    # Load the JSON configuration file\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = json.load(file)\n",
    "\n",
    "    # Update the value\n",
    "    config[key] = value\n",
    "\n",
    "    # Write the updated configuration back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(config, file, indent=4)\n",
    "        print(f\"{file_path} updated. {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------ollama--------------\n",
      "Id: 2567b2ae-b5d1-4214-92e9-ae28e523174e, Message: Configuration created\n",
      "ollama/env.json updated. configuration_id: 2567b2ae-b5d1-4214-92e9-ae28e523174e\n"
     ]
    },
    {
     "ename": "AIAPINotFoundException",
     "evalue": "Failed to post /configurations: Not Found, Could not create configuration because executable local-ai for scenario local-ai wasn't found.. \n Status Code: 404, Request ID:ee118d63-4fa1-4261-a185-f6e3b852cc33",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAIAPINotFoundException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conf \u001b[38;5;129;01min\u001b[39;00m conf_list:\n\u001b[1;32m      5\u001b[0m     parameter_bindings \u001b[38;5;241m=\u001b[39m [ParameterBinding(pb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m], pb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m pb \u001b[38;5;129;01min\u001b[39;00m conf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]]    \n\u001b[0;32m----> 6\u001b[0m     configuration \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscenario_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscenario_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecutable_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecutable_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameter_bindings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameter_bindings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------------\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscenario_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m--------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(configuration)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ai_api_client_sdk/resource_clients/configuration_client.py:55\u001b[0m, in \u001b[0;36mConfigurationClient.create\u001b[0;34m(self, name, scenario_id, executable_id, parameter_bindings, input_artifact_bindings, resource_group)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_artifact_bindings:\n\u001b[1;32m     54\u001b[0m     body[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_artifact_bindings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [iab\u001b[38;5;241m.\u001b[39mto_dict() \u001b[38;5;28;01mfor\u001b[39;00m iab \u001b[38;5;129;01min\u001b[39;00m input_artifact_bindings]\n\u001b[0;32m---> 55\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/configurations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ConfigurationCreateResponse\u001b[38;5;241m.\u001b[39mfrom_dict(response_dict)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ai_api_client_sdk/helpers/rest_client.py:140\u001b[0m, in \u001b[0;36mRestClient.post\u001b[0;34m(self, path, body, headers, resource_group)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m, body: Dict[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, headers: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    115\u001b[0m          resource_group: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request to the server.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    :param path: path of the endpoint the request should be sent to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    :rtype: dict\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_json\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_group\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ai_api_client_sdk/helpers/rest_client.py:99\u001b[0m, in \u001b[0;36mRestClient._handle_request\u001b[0;34m(self, method, path, params, body_json, headers, resource_group)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AIAPIInvalidRequestException(description\u001b[38;5;241m=\u001b[39merror_description, error_message\u001b[38;5;241m=\u001b[39merror_message,\n\u001b[1;32m     97\u001b[0m                                        error_code\u001b[38;5;241m=\u001b[39merror_code, request_id\u001b[38;5;241m=\u001b[39mrequest_id, details\u001b[38;5;241m=\u001b[39merror_details)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AIAPINotFoundException(description\u001b[38;5;241m=\u001b[39merror_description, error_message\u001b[38;5;241m=\u001b[39merror_message,\n\u001b[1;32m    100\u001b[0m                                  error_code\u001b[38;5;241m=\u001b[39merror_code, request_id\u001b[38;5;241m=\u001b[39mrequest_id, details\u001b[38;5;241m=\u001b[39merror_details)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m412\u001b[39m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AIAPIPreconditionFailedException(description\u001b[38;5;241m=\u001b[39merror_description, error_message\u001b[38;5;241m=\u001b[39merror_message,\n\u001b[1;32m    103\u001b[0m                                            error_code\u001b[38;5;241m=\u001b[39merror_code, request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[1;32m    104\u001b[0m                                            details\u001b[38;5;241m=\u001b[39merror_details)\n",
      "\u001b[0;31mAIAPINotFoundException\u001b[0m: Failed to post /configurations: Not Found, Could not create configuration because executable local-ai for scenario local-ai wasn't found.. \n Status Code: 404, Request ID:ee118d63-4fa1-4261-a185-f6e3b852cc33"
     ]
    }
   ],
   "source": [
    "# Create serving configurations\n",
    "conf_list = config[\"configurations\"]\n",
    "\n",
    "for conf in conf_list:\n",
    "    parameter_bindings = [ParameterBinding(pb['key'], pb['value']) for pb in conf[\"parameters\"]]    \n",
    "    configuration = client.configuration.create(\n",
    "        name=conf[\"name\"],\n",
    "        scenario_id=conf[\"scenario_id\"],\n",
    "        executable_id=conf[\"executable_id\"],\n",
    "        parameter_bindings=parameter_bindings,\n",
    "    )\n",
    "    print(f'--------------{conf[\"scenario_id\"]}--------------')\n",
    "    print(configuration)\n",
    "\n",
    "    # Update the configuration_id in env.json under the corresponding folder\n",
    "    # which will be used in continuos-deployment.ipynb to create deployment automatically.\n",
    "    update_json_file(f'{conf[\"executable_id\"]}/env.json',\"configuration_id\", configuration.id)\n",
    "    config_id = configuration.id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
